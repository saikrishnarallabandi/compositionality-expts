{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "gpu_id = 0  # set GPU id to use\n",
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# Start the session BEFORE importing tensorflow_fold\n",
    "# to avoid taking up all GPU memory\n",
    "sess = tf.Session(config=tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(allow_growth=True),\n",
    "    allow_soft_placement=False, log_device_placement=False))\n",
    "\n",
    "from models_shapes.nmn3_assembler import Assembler\n",
    "from models_shapes.nmn3_model import NMN3ModelAtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Module parameters\n",
    "H_im = 30\n",
    "W_im = 30\n",
    "num_choices = 2\n",
    "embed_dim_txt = 300\n",
    "embed_dim_nmn = 300\n",
    "lstm_dim = 256\n",
    "num_layers = 2\n",
    "encoder_dropout = False\n",
    "decoder_dropout = False\n",
    "decoder_sampling = False\n",
    "T_encoder = 15\n",
    "T_decoder = 8\n",
    "N = 256\n",
    "\n",
    "exp_name = \"shapes_gt_layout\"\n",
    "snapshot_name = \"00040000\"\n",
    "snapshot_file = './exp_shapes/tfmodel/%s/%s' % (exp_name, snapshot_name)\n",
    "\n",
    "# Data files\n",
    "vocab_shape_file = './exp_shapes/data/vocabulary_shape.txt'\n",
    "vocab_layout_file = './exp_shapes/data/vocabulary_layout.txt'\n",
    "# image_sets = ['train.large', 'train.med', 'train.small', 'train.tiny']\n",
    "image_sets = ['val']\n",
    "# image_sets = ['test']\n",
    "training_text_files = './exp_shapes/shapes_dataset/%s.query_str.txt'\n",
    "training_image_files = './exp_shapes/shapes_dataset/%s.input.npy'\n",
    "training_label_files = './exp_shapes/shapes_dataset/%s.output'\n",
    "image_mean_file = './exp_shapes/data/image_mean.npy'\n",
    "\n",
    "save_dir = './exp_shapes/results/%s/%s.%s' % (exp_name, snapshot_name + '_vis', '_'.join(image_sets))\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "with open(vocab_shape_file) as f:\n",
    "    vocab_shape_list = [s.strip() for s in f.readlines()]\n",
    "vocab_shape_dict = {vocab_shape_list[n]:n for n in range(len(vocab_shape_list))}\n",
    "num_vocab_txt = len(vocab_shape_list)\n",
    "\n",
    "assembler = Assembler(vocab_layout_file)\n",
    "num_vocab_nmn = len(assembler.module_names)\n",
    "\n",
    "# Load training data\n",
    "training_questions = []\n",
    "training_labels = []\n",
    "training_images_list = []\n",
    "\n",
    "for image_set in image_sets:\n",
    "    with open(training_text_files % image_set) as f:\n",
    "        training_questions += [l.strip() for l in f.readlines()]\n",
    "    with open(training_label_files % image_set) as f:\n",
    "        training_labels += [l.strip() == 'true' for l in f.readlines()]\n",
    "    training_images_list.append(np.load(training_image_files % image_set))\n",
    "\n",
    "num_questions = len(training_questions)\n",
    "training_images = np.concatenate(training_images_list)\n",
    "\n",
    "# Shuffle the training data\n",
    "# fix random seed for data repeatibility\n",
    "np.random.seed(3)\n",
    "shuffle_inds = np.random.permutation(num_questions)\n",
    "\n",
    "training_questions = [training_questions[idx] for idx in shuffle_inds]\n",
    "training_labels = [training_labels[idx] for idx in shuffle_inds]\n",
    "training_images = training_images[shuffle_inds]\n",
    "\n",
    "# number of training batches\n",
    "num_batches = np.ceil(num_questions / N)\n",
    "\n",
    "# Turn the questions into vocabulary indices\n",
    "text_seq_array = np.zeros((T_encoder, num_questions), np.int32)\n",
    "seq_length_array = np.zeros(num_questions, np.int32)\n",
    "for n_q in range(num_questions):\n",
    "    tokens = training_questions[n_q].split()\n",
    "    seq_length_array[n_q] = len(tokens)\n",
    "    for t in range(len(tokens)):\n",
    "        text_seq_array[t, n_q] = vocab_shape_dict[tokens[t]]\n",
    "        \n",
    "image_mean = np.load(image_mean_file)\n",
    "image_array = (training_images - image_mean).astype(np.float32)\n",
    "vqa_label_array = np.array(training_labels, np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Network inputs\n",
    "text_seq_batch = tf.placeholder(tf.int32, [None, None])\n",
    "seq_length_batch = tf.placeholder(tf.int32, [None])\n",
    "image_batch = tf.placeholder(tf.float32, [None, H_im, W_im, 3])\n",
    "expr_validity_batch = tf.placeholder(tf.bool, [None])\n",
    "\n",
    "# The model\n",
    "nmn3_model = NMN3ModelAtt(image_batch, text_seq_batch,\n",
    "    seq_length_batch, T_decoder=T_decoder,\n",
    "    num_vocab_txt=num_vocab_txt, embed_dim_txt=embed_dim_txt,\n",
    "    num_vocab_nmn=num_vocab_nmn, embed_dim_nmn=embed_dim_nmn,\n",
    "    lstm_dim=lstm_dim,\n",
    "    num_layers=num_layers, EOS_idx=assembler.EOS_idx,\n",
    "    encoder_dropout=encoder_dropout,\n",
    "    decoder_dropout=decoder_dropout,\n",
    "    decoder_sampling=decoder_sampling,\n",
    "    num_choices=num_choices)\n",
    "\n",
    "compiler = nmn3_model.compiler\n",
    "scores = nmn3_model.scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from models_shapes.nmn3_modules import Modules\n",
    "from models_shapes.nmn3_assembler import _module_input_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_feature_grid = nmn3_model.image_feat_grid\n",
    "word_vecs = nmn3_model.word_vecs\n",
    "atts = nmn3_model.atts\n",
    "\n",
    "image_feat_grid_ph = tf.placeholder(tf.float32, image_feature_grid.get_shape())\n",
    "word_vecs_ph = tf.placeholder(tf.float32, word_vecs.get_shape())\n",
    "modules = Modules(image_feat_grid_ph, word_vecs_ph, num_choices)\n",
    "\n",
    "batch_idx = tf.constant([0], tf.int32)\n",
    "time_idx = tf.placeholder(tf.int32, [1])\n",
    "input_0 = tf.placeholder(tf.float32, [1, 3, 3, 1])\n",
    "input_1 = tf.placeholder(tf.float32, [1, 3, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Manually construct each module outside TensorFlow fold for visualization\n",
    "with tf.variable_scope(\"neural_module_network/layout_execution\", reuse=True):\n",
    "    FindOutput = modules.FindModule(time_idx, batch_idx)\n",
    "    TransformOutput = modules.TransformModule(input_0, time_idx, batch_idx)\n",
    "    AndOutput = modules.AndModule(input_0, input_1, time_idx, batch_idx)\n",
    "    AnswerOutput = modules.AnswerModule(input_0, time_idx, batch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snapshot_saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "snapshot_saver.restore(sess, snapshot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_module(module_name, inputs, t, image_feat_grid_val, word_vecs_val):\n",
    "    feed_dict = {image_feat_grid_ph: image_feat_grid_val,\n",
    "                 word_vecs_ph: word_vecs_val,\n",
    "                 time_idx: [t]}\n",
    "    # print('evaluating module ' + module_name)\n",
    "    if 'input_0' in inputs:\n",
    "        feed_dict[input_0] = inputs['input_0']\n",
    "    if 'input_1' in inputs:\n",
    "        feed_dict[input_1] = inputs['input_1']\n",
    "    if module_name == \"_Find\":\n",
    "        result = sess.run(FindOutput, feed_dict)\n",
    "    elif module_name == \"_Transform\":\n",
    "        result = sess.run(TransformOutput, feed_dict)\n",
    "    elif module_name == \"_And\":\n",
    "        result = sess.run(AndOutput, feed_dict)\n",
    "    elif module_name == \"_Answer\":\n",
    "        result = sess.run(AnswerOutput, feed_dict)\n",
    "    else:\n",
    "        raise ValueError(\"invalid module name: \" + module_name)\n",
    "\n",
    "    return result\n",
    "\n",
    "def eval_expr(layout_tokens, image_feat_grid_val, word_vecs_val):\n",
    "    invalid_scores = np.array([[0, 0]], np.float32)\n",
    "    # Decoding Reverse Polish Notation with a stack\n",
    "    decoding_stack = []\n",
    "    all_output_stack = []\n",
    "    for t in range(len(layout_tokens)):\n",
    "        # decode a module/operation\n",
    "        module_idx = layout_tokens[t]\n",
    "        if module_idx == assembler.EOS_idx:\n",
    "            break\n",
    "        module_name = assembler.module_names[module_idx]\n",
    "        input_num = _module_input_num[module_name]\n",
    "\n",
    "        # Get the input from stack\n",
    "        inputs = {}\n",
    "        for n_input in range(input_num-1, -1, -1):\n",
    "            stack_top = decoding_stack.pop()\n",
    "            inputs[\"input_%d\" % n_input] = stack_top\n",
    "        result = eval_module(module_name, inputs, t,\n",
    "                             image_feat_grid_val, word_vecs_val)\n",
    "        decoding_stack.append(result)\n",
    "        all_output_stack.append((t, module_name, result[0]))\n",
    "\n",
    "    result = decoding_stack[0]\n",
    "    return result, all_output_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def expr2str(expr, indent=4):\n",
    "    name = expr['module']\n",
    "    input_str = []\n",
    "    if 'input_0' in expr:\n",
    "        input_str.append('\\n'+' '*indent+expr2str(expr['input_0'], indent+4))\n",
    "    if 'input_1' in expr:\n",
    "        input_str.append('\\n'+' '*indent+expr2str(expr['input_1'], indent+4))\n",
    "    expr_str = name[1:]+\"[\"+str(expr['time_idx'])+\"]\"+\"(\"+\", \".join(input_str)+\")\"\n",
    "    return expr_str\n",
    "\n",
    "def visualize(n):\n",
    "    n_begin = n\n",
    "    n_end = n + 1\n",
    "\n",
    "    # set up input and output tensors\n",
    "    h = sess.partial_run_setup(\n",
    "        [nmn3_model.predicted_tokens, image_feature_grid, word_vecs, atts, scores],\n",
    "        [text_seq_batch, seq_length_batch, image_batch,\n",
    "         compiler.loom_input_tensor, expr_validity_batch])\n",
    "\n",
    "    # Part 0 & 1: Run Convnet and generate module layout\n",
    "    tokens, image_feat_grid_val, word_vecs_val, atts_val = \\\n",
    "        sess.partial_run(h, (nmn3_model.predicted_tokens, image_feature_grid, word_vecs, atts),\n",
    "        feed_dict={text_seq_batch: text_seq_array[:, n_begin:n_end],\n",
    "                   seq_length_batch: seq_length_array[n_begin:n_end],\n",
    "                   image_batch: image_array[n_begin:n_end]})\n",
    "\n",
    "    # Assemble the layout tokens into network structure\n",
    "    expr_list, expr_validity_array = assembler.assemble(tokens)\n",
    "    labels = vqa_label_array[n_begin:n_end].astype(np.bool)\n",
    "\n",
    "    # Build TensorFlow Fold input for NMN\n",
    "    expr_feed = compiler.build_feed_dict(expr_list)\n",
    "    expr_feed[expr_validity_batch] = expr_validity_array\n",
    "\n",
    "    # Part 2: Run NMN and learning steps\n",
    "    scores_val = sess.partial_run(h, scores, feed_dict=expr_feed)\n",
    "    predictions = np.argmax(scores_val, axis=1).astype(np.bool)\n",
    "\n",
    "    layout_tokens = tokens.T[0]\n",
    "    _, all_output_stack = eval_expr(layout_tokens, image_feat_grid_val, word_vecs_val)\n",
    "    \n",
    "    plt.close('all')\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.subplot(3, 3, 1)\n",
    "    plt.imshow((image_array[n]+image_mean)[:, :, ::-1].astype(np.uint8))\n",
    "    plt.title(training_questions[n])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(3, 3, 2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.ones((3, 3, 3), np.float32))\n",
    "    plt.text(0, 1, 'Predicted layout:\\n\\n' + expr2str(expr_list[0])+\n",
    "             '\\n\\nlabel: '+str(labels[0])+'\\nprediction: '+str(predictions[0]))\n",
    "    plt.subplot(3, 3, 3)\n",
    "    plt.imshow(atts_val.reshape(atts_val.shape[:2]), interpolation='nearest', cmap='Reds')\n",
    "    encoder_words = [(vocab_shape_list[w]\n",
    "                     if n_w < seq_length_array[n_begin] else ' ')\n",
    "                     for n_w, w in enumerate(text_seq_array[:, n_begin])]\n",
    "    decoder_words = [(assembler.module_names[w][1:]+'[%d]'%n_w\n",
    "                      if w != assembler.EOS_idx else '<eos>')\n",
    "                     for n_w, w in enumerate(layout_tokens)]\n",
    "    plt.xticks(np.arange(T_encoder), encoder_words, rotation=90)\n",
    "    plt.yticks(np.arange(T_decoder), decoder_words)\n",
    "    plt.colorbar()\n",
    "    for t, module_name, results in all_output_stack:\n",
    "        result = all_output_stack[0][2]\n",
    "        plt.subplot(3, 3, t+4)\n",
    "        if results.ndim > 2:\n",
    "            plt.imshow(results[..., 0], interpolation='nearest', vmin=-1.5, vmax=1.5, cmap='Reds')\n",
    "            plt.axis('off')\n",
    "        else:\n",
    "            plt.imshow(results.reshape((1, 2)), interpolation='nearest', vmin=-1.5, vmax=1.5, cmap='Reds')\n",
    "            plt.xticks([0, 1], ['False', 'True'])\n",
    "        plt.title('output from '+module_name[1:]+\"[\"+str(t)+\"]\")\n",
    "        plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in range(100):\n",
    "    print('visualizing %d' % n)\n",
    "    visualize(n)\n",
    "    plt.savefig(os.path.join(save_dir, '%08d.jpg' % n))\n",
    "    plt.close('all')\n",
    "\n",
    "print('visualizations saved to', save_dir)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
